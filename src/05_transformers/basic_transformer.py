# -*- coding: utf-8 -*-
"""
ç¬¬åäºŒèŠ‚å®æˆ˜ï¼šä½¿ç”¨ç®€åŒ– Transformer é¢„æµ‹æ¯æ—¥æœ€ä½æ°”æ¸©ï¼ˆæ—¶é—´åºåˆ—å›å½’ï¼‰
ä»»åŠ¡ï¼šç”¨è¿‡å»30å¤©çš„æ°”æ¸©ï¼Œé¢„æµ‹ç¬¬31å¤©çš„æ°”æ¸©ï¼ˆè¿ç»­å€¼ï¼‰
å¯¹æ¯”ç¬¬åä¸€èŠ‚çš„ LSTMï¼Œç†è§£ Transformer å¦‚ä½•å¤„ç†åºåˆ—
"""

# ----------------------------
# ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥åº“ï¼ˆå¤ç”¨ç¬¬åä¸€èŠ‚æ•°æ®ï¼‰
# ----------------------------

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math
import matplotlib.pyplot as plt
import urllib.request
import os

torch.manual_seed(42)
np.random.seed(42)

# ----------------------------
# ç¬¬äºŒæ­¥ï¼šåŠ è½½å¹¶é¢„å¤„ç†æ•°æ®ï¼ˆåŒç¬¬åä¸€èŠ‚ï¼‰
# ----------------------------

url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv"
data_file = "daily-min-temperatures.csv"

if not os.path.exists(data_file):
    urllib.request.urlretrieve(url, data_file)

df = pd.read_csv(data_file)
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date')
df['Temp'] = pd.to_numeric(df['Temp'].astype(str).str.strip(), errors='coerce')
df = df.dropna()

# å½’ä¸€åŒ–
scaler = MinMaxScaler(feature_range=(0, 1))
temps_scaled = scaler.fit_transform(df['Temp'].values.reshape(-1, 1)).flatten()

# æ„é€ æ»‘åŠ¨çª—å£
seq_length = 30
def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i + seq_len])
        y.append(data[i + seq_len])
    return np.array(X), np.array(y)

X, y = create_sequences(temps_scaled, seq_length)

# åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
split_idx = int(0.8 * len(X))
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

# è½¬ä¸ºå¼ é‡ï¼šæ³¨æ„ Transformer è¾“å…¥æ˜¯ (batch, seq_len, 1)
X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)
y_train = torch.tensor(y_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)
y_test = torch.tensor(y_test, dtype=torch.float32)

# DataLoader
batch_size = 64
train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=False)
test_loader = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=False)

# ----------------------------
# ç¬¬ä¸‰æ­¥ï¼šå®ç°ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰
# ----------------------------

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        """
        ä¸ºåºåˆ—æ·»åŠ ä½ç½®ä¿¡æ¯
        :param d_model: æ¨¡å‹ç»´åº¦ï¼ˆæ­¤å¤„=1ï¼Œä½†é€šå¸¸>=32ï¼‰
        :param max_len: æœ€å¤§åºåˆ—é•¿åº¦
        """
        super(PositionalEncoding, self).__init__()
        # åˆ›å»ºä½ç½®ç¼–ç çŸ©é˜µ (max_len, d_model)
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (max_len, 1)
        div_term = torch.exp(
            torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model)
        )  # (d_model/2,)
        # å¶æ•°ç»´ç”¨ sinï¼Œå¥‡æ•°ç»´ç”¨ cos
        pe[:, 0::2] = torch.sin(position * div_term)  # æ‰€æœ‰è¡Œï¼Œå¶æ•°åˆ—
        pe[:, 1::2] = torch.cos(position * div_term)  # æ‰€æœ‰è¡Œï¼Œå¥‡æ•°åˆ—
        pe = pe.unsqueeze(0)  # (1, max_len, d_model)
        self.register_buffer('pe', pe)  # ä¸ä½œä¸ºæ¨¡å‹å‚æ•°ï¼Œä½†éšæ¨¡å‹ç§»åŠ¨åˆ°GPU

    def forward(self, x):
        """
        x: (batch, seq_len, d_model)
        è¿”å› x + ä½ç½®ç¼–ç ï¼ˆåªå–å‰ seq_len ä¸ªä½ç½®ï¼‰
        """
        x = x + self.pe[:, :x.size(1), :]
        return x

# ----------------------------
# ç¬¬å››æ­¥ï¼šæ„å»ºç®€åŒ– Transformer Encoder å±‚
# ----------------------------

class TransformerRegressor(nn.Module):
    def __init__(self, input_dim=1, d_model=32, nhead=4, num_layers=1, dim_feedforward=64, dropout=0.1):
        """
        ç®€åŒ–ç‰ˆ Transformer å›å½’æ¨¡å‹ï¼ˆä»… Encoderï¼‰
        :param input_dim: è¾“å…¥ç‰¹å¾ç»´åº¦ï¼ˆæ°”æ¸©=1ï¼‰
        :param d_model: Transformer å†…éƒ¨ç»´åº¦ï¼ˆå¿…é¡»èƒ½è¢« nhead æ•´é™¤ï¼‰
        :param nhead: å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°
        :param num_layers: Encoder å±‚æ•°
        :param dim_feedforward: å‰é¦ˆç½‘ç»œéšè—å±‚ç»´åº¦
        """
        super(TransformerRegressor, self).__init__()
        
        # ğŸŒŸ æ­¥éª¤1ï¼šå°†è¾“å…¥ä» input_dim æ˜ å°„åˆ° d_model
        self.input_projection = nn.Linear(input_dim, d_model)
        
        # ğŸŒŸ æ­¥éª¤2ï¼šä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(d_model, max_len=seq_length)
        
        # ğŸŒŸ æ­¥éª¤3ï¼šTransformer Encoder å±‚
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=True  # è¾“å…¥å½¢çŠ¶: (batch, seq_len, d_model)
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # ğŸŒŸ æ­¥éª¤4ï¼šå›å½’è¾“å‡ºå±‚ï¼ˆå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥ï¼‰
        self.regressor = nn.Linear(d_model, 1)

    def forward(self, x):
        """
        x: (batch, seq_len, input_dim=1)
        return: (batch,)
        """
        # 1. æŠ•å½±åˆ° d_model ç»´åº¦
        x = self.input_projection(x)  # (batch, seq_len, d_model)
        
        # 2. æ·»åŠ ä½ç½®ç¼–ç 
        x = self.pos_encoder(x)  # (batch, seq_len, d_model)
        
        # 3. Transformer Encoder
        x = self.transformer_encoder(x)  # (batch, seq_len, d_model)
        
        # 4. å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºç”¨äºå›å½’
        x = x[:, -1, :]  # (batch, d_model)
        
        # 5. å›å½’è¾“å‡º
        out = self.regressor(x)  # (batch, 1)
        return out.squeeze(-1)  # (batch,)

# ----------------------------
# ç¬¬äº”æ­¥ï¼šåˆ›å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
# ----------------------------

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ³¨æ„ï¼šd_model=32ï¼ˆä¸èƒ½ä¸º1ï¼Œå› ä¸º nhead=4 éœ€æ•´é™¤ï¼‰
model = TransformerRegressor(
    input_dim=1,
    d_model=32,
    nhead=4,
    num_layers=1,
    dim_feedforward=64,
    dropout=0.1
).to(device)

print(f"âœ… æ¨¡å‹å·²åˆ›å»ºï¼Œä½¿ç”¨è®¾å¤‡: {device}")
print(model)

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# ----------------------------
# ç¬¬å…­æ­¥ï¼šè®­ç»ƒæ¨¡å‹
# ----------------------------

print("\nğŸš€ å¼€å§‹è®­ç»ƒ Transformer...")

num_epochs = 50
train_losses = []

for epoch in range(num_epochs):
    model.train()
    total_loss = 0.0
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    avg_loss = total_loss / len(train_loader)
    train_losses.append(avg_loss)
    
    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}")

# ç»˜åˆ¶æŸå¤±æ›²çº¿
plt.figure(figsize=(8, 4))
plt.plot(train_losses, label='Transformer Training Loss')
plt.title('ğŸ“‰ Transformer è®­ç»ƒæŸå¤±')
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.legend()
plt.grid(True)
plt.show()

# ----------------------------
# ç¬¬ä¸ƒæ­¥ï¼šæµ‹è¯•ä¸è¯„ä¼°
# ----------------------------

model.eval()
test_preds = []
test_targets = []

with torch.no_grad():
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        test_preds.extend(outputs.cpu().numpy())
        test_targets.extend(targets.cpu().numpy())

# åå½’ä¸€åŒ–
test_preds = np.array(test_preds).reshape(-1, 1)
test_targets = np.array(test_targets).reshape(-1, 1)
test_preds_original = scaler.inverse_transform(test_preds).flatten()
test_targets_original = scaler.inverse_transform(test_targets).flatten()

mae = mean_absolute_error(test_targets_original, test_preds_original)
rmse = math.sqrt(mean_squared_error(test_targets_original, test_preds_original))

print(f"\nğŸ‰ Transformer æµ‹è¯•ç»“æœ:")
print(f"MAE: {mae:.2f} Â°C")
print(f"RMSE: {rmse:.2f} Â°C")

# å¯è§†åŒ–
plt.figure(figsize=(14, 6))
plt.plot(test_targets_original, label='çœŸå®æ°”æ¸©', color='steelblue')
plt.plot(test_preds_original, label='Transformer é¢„æµ‹', color='red', linestyle='--')
plt.title('ğŸŒ¡ï¸ Transformer æ°”æ¸©é¢„æµ‹ç»“æœï¼ˆæµ‹è¯•é›†ï¼‰')
plt.xlabel('æ—¶é—´æ­¥ï¼ˆå¤©ï¼‰')
plt.ylabel('æœ€ä½æ°”æ¸© (Â°C)')
plt.legend()
plt.grid(True)
plt.show()