"""
æ•°æ®é…ç½®ç®¡ç†æ¨¡å—

ç»Ÿä¸€ç®¡ç†é¡¹ç›®ä¸­æ‰€æœ‰æ•°æ®é›†çš„è·¯å¾„é…ç½®ï¼Œæ”¯æŒï¼š
- ç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„è‡ªåŠ¨åˆ‡æ¢
- å¤šç¯å¢ƒé…ç½®ï¼ˆå¼€å‘ã€ç”Ÿäº§ï¼‰
- æ•°æ®é›†è·¯å¾„éªŒè¯
- æ•°æ®é›†ä¿¡æ¯æŸ¥è¯¢
"""

import os
from pathlib import Path
from typing import Dict, Optional, Tuple

class DataConfig:
    """æ•°æ®é…ç½®ç®¡ç†ç±»"""
    
    def __init__(self):
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).parent.parent.parent
        
        # æ•°æ®æ ¹ç›®å½•ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
        self.data_root = self.project_root / "data"
        
        # æ•°æ®é›†é…ç½®
        self.datasets = {
            "cats_and_dogs": {
                "path": self.data_root / "cats_and_dogs",
                "train_dir": "train",
                "val_dir": "val", 
                "test_dir": "val",  # ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†
                "classes": ["cat", "dog"],
                "description": "çŒ«ç‹—äºŒåˆ†ç±»æ•°æ®é›†ï¼Œ275å¼ è®­ç»ƒå›¾ç‰‡ï¼Œ70å¼ éªŒè¯å›¾ç‰‡"
            },
            "fruits100": {
                "path": self.data_root / "fruits100",
                "train_dir": "train",
                "val_dir": "val",
                "test_dir": "val",  # ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†
                "num_classes": 100,
                "description": "æ°´æœåˆ†ç±»æ•°æ®é›†ï¼ŒåŒ…å«100ç§æ°´æœç±»å‹çš„å›¾åƒï¼Œæ”¯æŒå¤šåˆ†ç±»ä»»åŠ¡",
                "source": "https://www.modelscope.cn/datasets/tany0699/fruits100",
                "format": "JPGå›¾ç‰‡ï¼ŒæŒ‰æ–‡ä»¶å¤¹åˆ†ç±»ç»„ç»‡"
            },
            "cifar10": {
                "path": self.data_root / "cifar-10-python.tar.gz",
                "classes": ["airplane", "automobile", "bird", "cat", "deer", 
                           "dog", "frog", "horse", "ship", "truck"],
                "description": "CIFAR-10æ•°æ®é›†ï¼Œ10ä¸ªç±»åˆ«çš„32x32å½©è‰²å›¾ç‰‡"
            }
        }
    
    def get_dataset_path(self, dataset_name: str) -> Path:
        """è·å–æ•°æ®é›†è·¯å¾„"""
        if dataset_name not in self.datasets:
            raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")
        
        dataset_path = self.datasets[dataset_name]["path"]
        
        if not dataset_path.exists():
            raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        
        return dataset_path
    
    def get_cats_dogs_paths(self) -> Tuple[Path, Path, Path]:
        """è·å–çŒ«ç‹—æ•°æ®é›†çš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•è·¯å¾„"""
        dataset_path = self.get_dataset_path("cats_and_dogs")
        config = self.datasets["cats_and_dogs"]
        
        train_path = dataset_path / config["train_dir"]
        val_path = dataset_path / config["val_dir"]
        test_path = dataset_path / config["test_dir"]
        
        return train_path, val_path, test_path
    
    def get_fruits100_paths(self) -> Tuple[Path, Path, Path]:
        """è·å–æ°´æœæ•°æ®é›†çš„è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•è·¯å¾„"""
        dataset_path = self.get_dataset_path("fruits100")
        config = self.datasets["fruits100"]
        
        train_path = dataset_path / config["train_dir"]
        val_path = dataset_path / config["val_dir"]
        test_path = dataset_path / config["test_dir"]
        
        return train_path, val_path, test_path
    
    def get_dataset_info(self, dataset_name: str) -> Dict:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        if dataset_name not in self.datasets:
            raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")
        
        return self.datasets[dataset_name].copy()
    
    def list_datasets(self) -> Dict[str, str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†"""
        return {name: config["description"] 
                for name, config in self.datasets.items()}
    
    def validate_dataset(self, dataset_name: str) -> bool:
        """éªŒè¯æ•°æ®é›†æ˜¯å¦å­˜åœ¨ä¸”ç»“æ„æ­£ç¡®"""
        try:
            dataset_path = self.get_dataset_path(dataset_name)
            
            if dataset_name == "cats_and_dogs":
                train_path, val_path, _ = self.get_cats_dogs_paths()
                
                # æ£€æŸ¥ç›®å½•ç»“æ„
                required_dirs = [train_path, val_path]
                for dir_path in required_dirs:
                    if not dir_path.exists():
                        print(f"âŒ ç¼ºå°‘ç›®å½•: {dir_path}")
                        return False
                
                # æ£€æŸ¥ç±»åˆ«ç›®å½•
                for split_dir in [train_path, val_path]:
                    for class_name in self.datasets[dataset_name]["classes"]:
                        class_dir = split_dir / class_name
                        if not class_dir.exists():
                            print(f"âŒ ç¼ºå°‘ç±»åˆ«ç›®å½•: {class_dir}")
                            return False
            
            elif dataset_name == "fruits100":
                train_path, val_path, _ = self.get_fruits100_paths()
                
                # æ£€æŸ¥ç›®å½•ç»“æ„
                required_dirs = [train_path, val_path]
                for dir_path in required_dirs:
                    if not dir_path.exists():
                        print(f"âŒ ç¼ºå°‘ç›®å½•: {dir_path}")
                        return False
                
                # å¯¹äºæ°´æœæ•°æ®é›†ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å­ç›®å½•ï¼ˆç±»åˆ«ç›®å½•ï¼‰
                train_subdirs = [d for d in train_path.iterdir() if d.is_dir()]
                val_subdirs = [d for d in val_path.iterdir() if d.is_dir()]
                
                if len(train_subdirs) == 0:
                    print(f"âŒ è®­ç»ƒé›†ç›®å½•ä¸ºç©º: {train_path}")
                    return False
                
                if len(val_subdirs) == 0:
                    print(f"âŒ éªŒè¯é›†ç›®å½•ä¸ºç©º: {val_path}")
                    return False
                
                print(f"âœ… å‘ç° {len(train_subdirs)} ä¸ªè®­ç»ƒç±»åˆ«ï¼Œ{len(val_subdirs)} ä¸ªéªŒè¯ç±»åˆ«")
                
                print(f"âœ… æ•°æ®é›† {dataset_name} éªŒè¯é€šè¿‡")
                return True
                
        except Exception as e:
            print(f"âŒ æ•°æ®é›†éªŒè¯å¤±è´¥: {e}")
            return False
    
    def get_relative_path(self, dataset_name: str) -> str:
        """è·å–ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•çš„æ•°æ®é›†è·¯å¾„"""
        dataset_path = self.get_dataset_path(dataset_name)
        try:
            # å°è¯•è·å–ç›¸å¯¹è·¯å¾„
            relative_path = os.path.relpath(dataset_path)
            return relative_path
        except ValueError:
            # å¦‚æœæ— æ³•è·å–ç›¸å¯¹è·¯å¾„ï¼Œè¿”å›ç»å¯¹è·¯å¾„
            return str(dataset_path)

# å…¨å±€æ•°æ®é…ç½®å®ä¾‹
data_config = DataConfig()

# ä¾¿æ·å‡½æ•°
def get_cats_dogs_paths():
    """è·å–çŒ«ç‹—æ•°æ®é›†è·¯å¾„çš„ä¾¿æ·å‡½æ•°"""
    return data_config.get_cats_dogs_paths()

def get_fruits100_paths():
    """è·å–æ°´æœæ•°æ®é›†è·¯å¾„çš„ä¾¿æ·å‡½æ•°"""
    return data_config.get_fruits100_paths()

def get_dataset_path(dataset_name: str):
    """è·å–æ•°æ®é›†è·¯å¾„çš„ä¾¿æ·å‡½æ•°"""
    return data_config.get_dataset_path(dataset_name)

def validate_all_datasets():
    """éªŒè¯æ‰€æœ‰æ•°æ®é›†"""
    print("ğŸ” éªŒè¯æ•°æ®é›†...")
    for dataset_name in data_config.datasets.keys():
        data_config.validate_dataset(dataset_name)

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é…ç½®
    print("ğŸ“Š æ•°æ®é…ç½®æµ‹è¯•")
    print("=" * 50)
    
    # åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†
    print("\nğŸ“‹ å¯ç”¨æ•°æ®é›†:")
    for name, desc in data_config.list_datasets().items():
        print(f"  â€¢ {name}: {desc}")
    
    # éªŒè¯æ•°æ®é›†
    print("\nğŸ” éªŒè¯æ•°æ®é›†:")
    validate_all_datasets()
    
    # æ˜¾ç¤ºè·¯å¾„ä¿¡æ¯
    print("\nğŸ“ è·¯å¾„ä¿¡æ¯:")
    try:
        train_path, val_path, test_path = get_cats_dogs_paths()
        print(f"  è®­ç»ƒé›†: {train_path}")
        print(f"  éªŒè¯é›†: {val_path}")
        print(f"  æµ‹è¯•é›†: {test_path}")
    except Exception as e:
        print(f"  âŒ è·å–è·¯å¾„å¤±è´¥: {e}")