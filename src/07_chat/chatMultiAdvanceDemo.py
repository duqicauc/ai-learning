import httpx
from openai import OpenAI
import tiktoken
from typing import List, Dict
import os

class AdvancedChatManager:
    """é«˜çº§å¤šè½®å¯¹è¯ç®¡ç†å™¨ï¼Œæ”¯æŒtokenç®¡ç†å’Œå¯¹è¯ç²¾ç®€"""
    
    def __init__(self, max_tokens=4000, summarize_interval=5):
        """
        åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨
        
        Args:
            max_tokens: æœ€å¤§tokenæ•°é™åˆ¶
            summarize_interval: æ¯éš”å¤šå°‘è½®è¿›è¡Œå¯¹è¯ç²¾ç®€
        """
        self.max_tokens = max_tokens
        self.summarize_interval = summarize_interval
        self.conversation_history = []
        self.conversation_count = 0
        self.total_tokens_used = 0
        
        # åˆå§‹åŒ–tokenç¼–ç å™¨
        try:
            self.encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        except:
            # å¦‚æœæ— æ³•è·å–ç‰¹å®šæ¨¡å‹çš„ç¼–ç å™¨ï¼Œä½¿ç”¨é€šç”¨ç¼–ç å™¨
            self.encoding = tiktoken.get_encoding("cl100k_base")
        
        # åˆ›å»ºHTTPå®¢æˆ·ç«¯
        self.http_client = httpx.Client(
            verify=False,
            timeout=30.0
        )
        
        # é…ç½®APIå¯†é’¥
        api_key = os.getenv("SILICONFLOW_API_KEY")
        if not api_key:
            print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY")
            print("   å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®ï¼š")
            print("   1. åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : SILICONFLOW_API_KEY=your-api-key")
            print("   2. æˆ–åœ¨å‘½ä»¤è¡Œä¸­è®¾ç½®: set SILICONFLOW_API_KEY=your-api-key")
            return None
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            base_url="https://api.siliconflow.cn/v1",
            api_key=api_key,
            http_client=self.http_client
        )
        
        # åˆå§‹åŒ–ç³»ç»Ÿæ¶ˆæ¯
        self.system_message = {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚ä¿æŒå›ç­”ç®€æ´æ˜äº†ã€‚"
        }
        self.conversation_history.append(self.system_message)
    
    def count_tokens(self, messages: List[Dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„tokenæ•°é‡"""
        total_tokens = 0
        for message in messages:
            # è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„tokenæ•°
            message_tokens = len(self.encoding.encode(message["content"]))
            total_tokens += message_tokens
        return total_tokens
    
    def get_conversation_summary(self, messages: List[Dict]) -> str:
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        try:
            # æ„å»ºæ‘˜è¦è¯·æ±‚
            summary_messages = [
                {
                    "role": "system",
                    "content": "è¯·å°†ä»¥ä¸‹å¯¹è¯å†…å®¹æ€»ç»“æˆç®€æ´çš„æ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ã€‚æ‘˜è¦åº”è¯¥åœ¨100å­—ä»¥å†…ã€‚"
                },
                {
                    "role": "user",
                    "content": f"è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼š\n{json.dumps(messages, ensure_ascii=False, indent=2)}"
                }
            ]
            
            response = self.client.chat.completions.create(
                model="Qwen/Qwen2.5-7B-Instruct",
                messages=summary_messages,
                temperature=0.3,
                max_tokens=200
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸  æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            # å¦‚æœæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›ç®€å•çš„æ–‡æœ¬æ‘˜è¦
            return f"å¯¹è¯æ‘˜è¦ï¼šåŒ…å«{len(messages)}æ¡æ¶ˆæ¯çš„å¯¹è¯å†…å®¹"
    
    def compress_conversation_history(self):
        """å‹ç¼©å¯¹è¯å†å²ï¼Œä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„å¯¹è¯"""
        if len(self.conversation_history) <= 3:  # ç³»ç»Ÿæ¶ˆæ¯ + è‡³å°‘ä¸€è½®å¯¹è¯
            return
        
        print(f"\nğŸ”„ æ­£åœ¨å‹ç¼©å¯¹è¯å†å²...")
        print(f"   å‹ç¼©å‰ï¼š{len(self.conversation_history)} æ¡æ¶ˆæ¯")
        
        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
        system_msg = self.conversation_history[0]
        
        # è·å–éœ€è¦å‹ç¼©çš„æ¶ˆæ¯ï¼ˆé™¤äº†ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘2è½®å¯¹è¯ï¼‰
        recent_messages = self.conversation_history[-4:]  # ä¿ç•™æœ€è¿‘2è½®å¯¹è¯ï¼ˆ4æ¡æ¶ˆæ¯ï¼‰
        messages_to_compress = self.conversation_history[1:-4]  # éœ€è¦å‹ç¼©çš„æ¶ˆæ¯
        
        if messages_to_compress:
            # ç”Ÿæˆæ‘˜è¦
            summary = self.get_conversation_summary(messages_to_compress)
            
            # åˆ›å»ºæ‘˜è¦æ¶ˆæ¯
            summary_message = {
                "role": "system",
                "content": f"[å¯¹è¯å†å²æ‘˜è¦] {summary}"
            }
            
            # é‡æ„å¯¹è¯å†å²ï¼šç³»ç»Ÿæ¶ˆæ¯ + æ‘˜è¦ + æœ€è¿‘çš„å¯¹è¯
            self.conversation_history = [system_msg, summary_message] + recent_messages
            
            print(f"   å‹ç¼©åï¼š{len(self.conversation_history)} æ¡æ¶ˆæ¯")
            print(f"   ğŸ“ ç”Ÿæˆæ‘˜è¦ï¼š{summary[:50]}...")
        else:
            print("   æ— éœ€å‹ç¼©")
    
    def add_user_message(self, content: str):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        self.conversation_history.append({"role": "user", "content": content})
    
    def add_assistant_message(self, content: str):
        """æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯"""
        self.conversation_history.append({"role": "assistant", "content": content})
        self.conversation_count += 1
        
        # æ£€æŸ¥tokenä½¿ç”¨æƒ…å†µ
        current_tokens = self.count_tokens(self.conversation_history)
        usage_percent = (current_tokens / self.max_tokens) * 100
        
        print(f"\nğŸ“Š ç¬¬{self.conversation_count}è½®å¯¹è¯å®Œæˆ")
        print(f"   å½“å‰tokenæ•°ï¼š{current_tokens}/{self.max_tokens} ({usage_percent:.1f}%)")
        
        # å‹ç¼©é€»è¾‘ï¼šä¼˜å…ˆçº§æ£€æŸ¥
        should_compress = False
        compress_reason = ""
        
        # 1. ç´§æ€¥å‹ç¼©ï¼šè¶…è¿‡100%ç«‹å³å‹ç¼©
        if current_tokens > self.max_tokens:
            should_compress = True
            compress_reason = f"ğŸš¨ Tokenä½¿ç”¨ç‡è¶…è¿‡100% ({usage_percent:.1f}%)"
        
        # 2. é¢„é˜²æ€§å‹ç¼©ï¼šè¶…è¿‡90%ä¸”è¾¾åˆ°å‹ç¼©é—´éš”
        elif (current_tokens > self.max_tokens * 0.9 and 
              self.conversation_count % self.summarize_interval == 0):
            should_compress = True
            compress_reason = f"âš ï¸  Tokenä½¿ç”¨ç‡è¿‡é«˜ ({usage_percent:.1f}%) ä¸”è¾¾åˆ°å‹ç¼©é—´éš”"
        
        # 3. å®šæœŸå‹ç¼©ï¼šè¾¾åˆ°å‹ç¼©é—´éš”ä¸”è¶…è¿‡80%
        elif (self.conversation_count % self.summarize_interval == 0 and 
              current_tokens > self.max_tokens * 0.8):
            should_compress = True
            compress_reason = f"ğŸ”„ å®šæœŸå‹ç¼© ({usage_percent:.1f}%)"
        
        if should_compress:
            print(f"   {compress_reason}")
            self.compress_conversation_history()
    
    def get_conversation_stats(self) -> Dict:
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        current_tokens = self.count_tokens(self.conversation_history)
        return {
            "total_rounds": self.conversation_count,
            "total_messages": len(self.conversation_history) - 1,  # å‡å»ç³»ç»Ÿæ¶ˆæ¯
            "current_tokens": current_tokens,
            "max_tokens": self.max_tokens,
            "token_usage_percent": (current_tokens / self.max_tokens) * 100
        }
    
    def chat(self, user_input: str) -> str:
        """å‘é€èŠå¤©è¯·æ±‚å¹¶è¿”å›å›å¤"""
        self.add_user_message(user_input)
        
        # æ£€æŸ¥æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åæ˜¯å¦éœ€è¦ç´§æ€¥å‹ç¼©
        current_tokens = self.count_tokens(self.conversation_history)
        if current_tokens > self.max_tokens:
            usage_percent = (current_tokens / self.max_tokens) * 100
            print(f"\nğŸš¨ ç´§æ€¥å‹ç¼©ï¼šæ·»åŠ ç”¨æˆ·æ¶ˆæ¯åtokenä½¿ç”¨ç‡ {usage_percent:.1f}%")
            self.compress_conversation_history()
        
        try:
            response = self.client.chat.completions.create(
                model="Qwen/Qwen2.5-7B-Instruct",
                messages=self.conversation_history,
                temperature=0.7,
                max_tokens=500
            )
            
            ai_response = response.choices[0].message.content
            self.add_assistant_message(ai_response)
            
            return ai_response
            
        except Exception as e:
            # å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œç§»é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯
            self.conversation_history.pop()
            raise e
    
    def show_history(self):
        """æ˜¾ç¤ºå¯¹è¯å†å²"""
        stats = self.get_conversation_stats()
        print(f"\nğŸ“š å¯¹è¯å†å² (å…±{stats['total_messages']}æ¡æ¶ˆæ¯ï¼Œ{stats['current_tokens']} tokens)")
        print(f"   Tokenä½¿ç”¨ç‡: {stats['token_usage_percent']:.1f}%")
        print("-" * 50)
        
        for i, msg in enumerate(self.conversation_history[1:], 1):  # è·³è¿‡ç³»ç»Ÿæ¶ˆæ¯
            role = "æ‚¨" if msg["role"] == "user" else "AI" if msg["role"] == "assistant" else "æ‘˜è¦"
            content = msg["content"][:80] + "..." if len(msg["content"]) > 80 else msg["content"]
            print(f"   {i}. {role}: {content}")
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = [self.system_message]
        self.conversation_count = 0
        print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…ç©º")
    
    def close(self):
        """å…³é—­å®¢æˆ·ç«¯è¿æ¥"""
        if self.http_client:
            self.http_client.close()

def test_advanced_multi_turn_chat():
    """é«˜çº§å¤šè½®å¯¹è¯æ¼”ç¤º"""
    chat_manager = AdvancedChatManager(max_tokens=2000, summarize_interval=3)  # é™ä½é˜ˆå€¼ä¾¿äºæ¼”ç¤º
    
    try:
        print("ğŸš€ é«˜çº§å¤šè½®å¯¹è¯æ¼”ç¤ºå¯åŠ¨...")
        print("ğŸ”— è¿æ¥åˆ° SiliconFlow API...")
        print("\n" + "="*60)
        print("ğŸ’¬ é«˜çº§å¤šè½®å¯¹è¯æ¨¡å¼ (æ™ºèƒ½Tokenç®¡ç†)")
        print("="*60)
        print("ğŸ“ å¯ç”¨å‘½ä»¤:")
        print("   - ç›´æ¥è¾“å…¥æ–‡å­—è¿›è¡Œå¯¹è¯")
        print("   - '/history' - æŸ¥çœ‹å¯¹è¯å†å²å’Œtokenç»Ÿè®¡")
        print("   - '/stats' - æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
        print("   - '/clear' - æ¸…ç©ºå¯¹è¯å†å²")
        print("   - '/help' - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        print("   - '/quit' æˆ– '/exit' - é€€å‡ºç¨‹åº")
        print("="*60)
        print(f"âš™ï¸  é…ç½®: æœ€å¤§{chat_manager.max_tokens} tokensï¼Œæ¯{chat_manager.summarize_interval}è½®è‡ªåŠ¨ç²¾ç®€")
        
        while True:
            # è·å–ç”¨æˆ·è¾“å…¥
            try:
                stats = chat_manager.get_conversation_stats()
                prompt = f"\n[ç¬¬{stats['total_rounds'] + 1}è½®] æ‚¨ ({stats['current_tokens']} tokens): "
                user_input = input(prompt).strip()
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ£€æµ‹åˆ° Ctrl+Cï¼Œæ­£åœ¨é€€å‡º...")
                break
            except EOFError:
                print("\n\nğŸ‘‹ è¾“å…¥ç»“æŸï¼Œæ­£åœ¨é€€å‡º...")
                break
            
            # å¤„ç†ç©ºè¾“å…¥
            if not user_input:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                continue
            
            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                command = user_input.lower()
                
                if command in ['/quit', '/exit']:
                    print("ğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨é«˜çº§å¤šè½®å¯¹è¯æ¼”ç¤º")
                    break
                elif command == '/help':
                    print("\nğŸ“– å¸®åŠ©ä¿¡æ¯:")
                    print("   - ç›´æ¥è¾“å…¥æ–‡å­—è¿›è¡Œå¯¹è¯")
                    print("   - '/history' - æŸ¥çœ‹å¯¹è¯å†å²å’Œtokenç»Ÿè®¡")
                    print("   - '/stats' - æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
                    print("   - '/clear' - æ¸…ç©ºå¯¹è¯å†å²")
                    print("   - '/help' - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
                    print("   - '/quit' æˆ– '/exit' - é€€å‡ºç¨‹åº")
                    continue
                elif command == '/history':
                    chat_manager.show_history()
                    continue
                elif command == '/stats':
                    stats = chat_manager.get_conversation_stats()
                    print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
                    print(f"   - å¯¹è¯è½®æ•°: {stats['total_rounds']}")
                    print(f"   - æ¶ˆæ¯æ€»æ•°: {stats['total_messages']}")
                    print(f"   - å½“å‰tokens: {stats['current_tokens']}")
                    print(f"   - æœ€å¤§tokens: {stats['max_tokens']}")
                    print(f"   - ä½¿ç”¨ç‡: {stats['token_usage_percent']:.1f}%")
                    continue
                elif command == '/clear':
                    chat_manager.clear_history()
                    continue
                else:
                    print(f"âŒ æœªçŸ¥å‘½ä»¤: {user_input}")
                    print("ğŸ’¡ è¾“å…¥ '/help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
                    continue
            
            try:
                print("ğŸ¤– AIæ­£åœ¨æ€è€ƒ...")
                ai_response = chat_manager.chat(user_input)
                print(f"ğŸ¤– AI: {ai_response}")
                
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
                print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        final_stats = chat_manager.get_conversation_stats()
        print(f"\nğŸ“Š ä¼šè¯ç»“æŸç»Ÿè®¡:")
        print(f"   - æ€»å¯¹è¯è½®æ•°: {final_stats['total_rounds']}")
        print(f"   - æ€»æ¶ˆæ¯æ•°: {final_stats['total_messages']}")
        print(f"   - æœ€ç»ˆtokenæ•°: {final_stats['current_tokens']}")
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–é”™è¯¯: {str(e)}")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
        print("   3. å°è¯•ä½¿ç”¨VPN")
        
    finally:
        chat_manager.close()

def test_auto_compression():
    """è‡ªåŠ¨å‹ç¼©åŠŸèƒ½æµ‹è¯•"""
    print("ğŸ§ª è‡ªåŠ¨å‹ç¼©åŠŸèƒ½æµ‹è¯•...")
    chat_manager = AdvancedChatManager(max_tokens=1000, summarize_interval=2)  # æ›´ä½çš„é˜ˆå€¼
    
    try:
        # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
        test_conversations = [
            "ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹",
            "Pythonæœ‰å“ªäº›ä¸»è¦çš„åº”ç”¨é¢†åŸŸï¼Ÿ",
            "æˆ‘åº”è¯¥ä»å“ªäº›åŸºç¡€çŸ¥è¯†å¼€å§‹å­¦ä¹ ï¼Ÿ",
            "èƒ½æ¨èä¸€äº›å¥½çš„Pythonå­¦ä¹ èµ„æºå—ï¼Ÿ",
            "å­¦ä¹ Pythonå¤§æ¦‚éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ",
            "æˆ‘åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­é‡åˆ°å›°éš¾è¯¥æ€ä¹ˆåŠï¼Ÿ"
        ]
        
        for i, user_message in enumerate(test_conversations, 1):
            print(f"\n[æµ‹è¯•è½®æ¬¡ {i}]")
            print(f"ğŸ‘¤ ç”¨æˆ·: {user_message}")
            
            try:
                ai_response = chat_manager.chat(user_message)
                print(f"ğŸ¤– AI: {ai_response[:100]}...")
                
                # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                stats = chat_manager.get_conversation_stats()
                print(f"ğŸ“Š å½“å‰çŠ¶æ€: {stats['current_tokens']} tokens ({stats['token_usage_percent']:.1f}%)")
                
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
                break
        
        # æ˜¾ç¤ºæœ€ç»ˆå†å²
        print(f"\nğŸ“š æœ€ç»ˆå¯¹è¯å†å²:")
        chat_manager.show_history()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    finally:
        chat_manager.close()

def main():
    """ä¸»å‡½æ•°ï¼Œæä¾›é€‰æ‹©èœå•"""
    print("ğŸ¯ é«˜çº§èŠå¤©æ¼”ç¤ºç¨‹åº")
    print("="*40)
    print("è¯·é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:")
    print("1. äº¤äº’å¼é«˜çº§å¤šè½®å¯¹è¯")
    print("2. è‡ªåŠ¨å‹ç¼©åŠŸèƒ½æµ‹è¯•")
    print("3. é€€å‡ºç¨‹åº")
    print("="*40)
    
    while True:
        try:
            choice = input("è¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
            
            if choice == "1":
                print("\nğŸš€ å¯åŠ¨äº¤äº’å¼é«˜çº§å¤šè½®å¯¹è¯...")
                test_advanced_multi_turn_chat()
                break
            elif choice == "2":
                print("\nğŸš€ å¯åŠ¨è‡ªåŠ¨å‹ç¼©åŠŸèƒ½æµ‹è¯•...")
                test_auto_compression()
                break
            elif choice == "3":
                print("ğŸ‘‹ å†è§ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
            break
        except EOFError:
            print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
            break

if __name__ == "__main__":
    main()