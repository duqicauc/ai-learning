import ssl
import httpx
from openai import OpenAI
import os
import json
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def create_ssl_context():
    """Create SSL context that bypasses certificate verification"""
    context = ssl.create_default_context()
    context.check_hostname = False
    context.verify_mode = ssl.CERT_NONE
    return context

def test_stream_chat():
    """Test streaming chat with proper error handling"""
    try:
        # é…ç½®APIå¯†é’¥
        api_key = os.getenv("SILICONFLOW_API_KEY")
        if not api_key:
            print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ SILICONFLOW_API_KEY")
            print("   å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®ï¼š")
            print("   1. åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : SILICONFLOW_API_KEY=your-api-key")
            print("   2. æˆ–åœ¨å‘½ä»¤è¡Œä¸­è®¾ç½®: set SILICONFLOW_API_KEY=your-api-key")
            return
        
        # Create HTTP client with SSL bypass
        http_client = httpx.Client(
            verify=False,  # Bypass SSL verification
            timeout=30.0
        )
        
        # Create OpenAI client with custom HTTP client
        client = OpenAI(
            base_url="https://api.siliconflow.cn/v1",
            api_key=api_key,
            http_client=http_client
        )
        
        print("å¼€å§‹æ€ç»´é“¾æ¨ç†æ¼”ç¤º...")
        print("è¿æ¥åˆ° SiliconFlow API...")
        
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-R1",  # Updated to a more stable model
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚"},
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"},
            ],
            stream=True,
            temperature=0.7,
            max_tokens=500
        )
        
        print("\n=== æ€è€ƒè¿‡ç¨‹ ===")
        reasoning_content = ""
        content = ""
        reasoning_started = False
        
        # éå†æµå¼å“åº”çš„æ¯ä¸ªæ•°æ®å—
        for chunk in response:
            # å¤„ç†æ€è€ƒè¿‡ç¨‹å†…å®¹ï¼ˆreasoning_contentï¼‰
            if chunk.choices[0].delta.reasoning_content:
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ”¶åˆ°æ€è€ƒå†…å®¹ï¼Œæ ‡è®°æ€è€ƒé˜¶æ®µå¼€å§‹
                if not reasoning_started:
                    reasoning_started = True
                # ç´¯ç§¯æ€è€ƒè¿‡ç¨‹çš„å®Œæ•´å†…å®¹
                reasoning_content += chunk.choices[0].delta.reasoning_content
                # å®æ—¶è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œä¸æ¢è¡Œï¼Œç«‹å³åˆ·æ–°ç¼“å†²åŒº
                print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
            
            # å¤„ç†æœ€ç»ˆå›ç­”å†…å®¹ï¼ˆcontentï¼‰
            elif chunk.choices[0].delta.content:
                # å¦‚æœä¹‹å‰æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œç°åœ¨å¼€å§‹è¾“å‡ºæœ€ç»ˆå›ç­”ï¼Œéœ€è¦æ·»åŠ åˆ†éš”æ ‡é¢˜
                if reasoning_started:
                    print("\n\n=== æœ€ç»ˆå›ç­” ===")
                    reasoning_started = False  # æ ‡è®°æ€è€ƒé˜¶æ®µç»“æŸ
                # ç´¯ç§¯æœ€ç»ˆå›ç­”çš„å®Œæ•´å†…å®¹
                content += chunk.choices[0].delta.content
                # å®æ—¶è¾“å‡ºæœ€ç»ˆå›ç­”ï¼Œä¸æ¢è¡Œï¼Œç«‹å³åˆ·æ–°ç¼“å†²åŒº
                print(chunk.choices[0].delta.content, end="", flush=True)
        
        print(f"\n\næ¼”ç¤ºå®Œæˆã€‚æ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(reasoning_content)} å­—ç¬¦ï¼Œå›ç­”é•¿åº¦: {len(content)} å­—ç¬¦")
        
    except Exception as e:
        print(f"âŒ è¿æ¥é”™è¯¯: {str(e)}")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
        print("   3. å°è¯•ä½¿ç”¨VPN")
        
    finally:
        # Clean up HTTP client
        if 'http_client' in locals():
            http_client.close()

if __name__ == "__main__":
    test_stream_chat()
