# -*- coding: utf-8 -*-
"""
ç¬¬ä¸ƒèŠ‚å®æˆ˜ï¼šç”¨ CNN åˆ†ç±» MNIST æ‰‹å†™æ•°å­—
ç›®æ ‡ï¼šä»é›¶æ­å»ºã€è®­ç»ƒã€è¯„ä¼°ã€å¯è§†åŒ–ä¸€ä¸ªçœŸå® CNN æ¨¡å‹
"""

# ----------------------------
# ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥æ‰€éœ€åº“
# ----------------------------

import torch                     # PyTorch æ ¸å¿ƒåº“ï¼Œæä¾›å¼ é‡å’Œè‡ªåŠ¨å¾®åˆ†
import torch.nn as nn            # ç¥ç»ç½‘ç»œæ¨¡å—ï¼ˆå¦‚ Conv2d, Linear, ReLUï¼‰
import torch.optim as optim      # ä¼˜åŒ–å™¨ï¼ˆå¦‚ Adam, SGDï¼‰
from torchvision import datasets, transforms  # torchvisionï¼šè®¡ç®—æœºè§†è§‰ä¸“ç”¨å·¥å…·
from torch.utils.data import DataLoader       # æ•°æ®åŠ è½½å™¨
import matplotlib.pyplot as plt               # ç»˜å›¾åº“ï¼Œç”¨äºå¯è§†åŒ–

# ----------------------------
# ç¬¬äºŒæ­¥ï¼šè®¾ç½®è®¡ç®—è®¾å¤‡ï¼ˆCPU æˆ– GPUï¼‰
# ----------------------------

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPUï¼ˆCUDAï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
# è¯´æ˜ï¼šè‹¥æœ‰ NVIDIA GPU ä¸”å®‰è£…äº† CUDAï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨ GPU åŠ é€Ÿè®­ç»ƒï¼›
# å¦åˆ™å›é€€åˆ° CPUï¼ˆé€Ÿåº¦æ…¢ä½†èƒ½è¿è¡Œï¼‰

# ----------------------------
# ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é¢„å¤„ç†ä¸åŠ è½½
# ----------------------------

# å®šä¹‰å›¾åƒå˜æ¢ï¼ˆTransformsï¼‰ï¼šå°†åŸå§‹å›¾åƒè½¬ä¸ºæ¨¡å‹èƒ½å¤„ç†çš„å¼ é‡
transform = transforms.Compose([
    # ToTensor() ä¼šåšä¸¤ä»¶äº‹ï¼š
    # 1. å°† PIL å›¾åƒï¼ˆ0~255 çš„æ•´æ•°ï¼‰è½¬ä¸º PyTorch å¼ é‡ï¼›
    # 2. è‡ªåŠ¨å°†åƒç´ å€¼é™¤ä»¥ 255ï¼Œå½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´ï¼ˆæœ‰åˆ©äºè®­ç»ƒç¨³å®šï¼‰
    transforms.ToTensor(),
])

# ä¸‹è½½å¹¶åŠ è½½ MNIST è®­ç»ƒé›†
# root: æ•°æ®å­˜å‚¨è·¯å¾„ï¼ˆè‡ªåŠ¨åˆ›å»º ./data æ–‡ä»¶å¤¹ï¼‰
# train=True: åŠ è½½è®­ç»ƒé›†ï¼ˆ60,000 å¼ ï¼‰
# download=True: å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œè‡ªåŠ¨ä»ç½‘ä¸Šä¸‹è½½
# transform=transform: å¯¹æ¯å¼ å›¾åº”ç”¨ä¸Šé¢å®šä¹‰çš„å˜æ¢
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)

# åŠ è½½ MNIST æµ‹è¯•é›†ï¼ˆ10,000 å¼ ï¼‰
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# æ‰“å°æ•°æ®é›†ä¿¡æ¯
print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾, æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾")

# ----------------------------
# ç¬¬å››æ­¥ï¼šåˆ›å»º DataLoaderï¼ˆæ•°æ®â€œå¿«é€’æ‰“åŒ…å‘˜â€ï¼‰
# ----------------------------

batch_size = 64  # æ¯æ¬¡è®­ç»ƒé€å…¥æ¨¡å‹çš„å›¾åƒæ•°é‡ï¼ˆæ‰¹é‡å¤§å°ï¼‰

# DataLoader çš„ä½œç”¨ï¼š
# - æŒ‰ batch_size æ‰“åŒ…æ•°æ®ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½å…¨éƒ¨æ•°æ®ï¼‰
# - shuffle=Trueï¼šæ¯ä¸ª epoch å¼€å§‹å‰æ‰“ä¹±è®­ç»ƒæ•°æ®é¡ºåºï¼ˆé˜²æ­¢æ¨¡å‹è®°ä½é¡ºåºï¼‰
# - num_workers=0ï¼ˆé»˜è®¤ï¼‰ï¼šå•çº¿ç¨‹åŠ è½½ï¼ˆæ•™å­¦ç¯å¢ƒå®‰å…¨ï¼‰ï¼›å®é™…å¯ç”¨å¤šçº¿ç¨‹åŠ é€Ÿ
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  # æµ‹è¯•é›†æ— éœ€æ‰“ä¹±

print(f"âœ… æ‰¹æ¬¡å¤§å°: {batch_size}")
print(f"âœ… æ¯ä¸ª epoch æœ‰ {len(train_loader)} ä¸ªè®­ç»ƒæ‰¹æ¬¡")

# ----------------------------
# ç¬¬äº”æ­¥ï¼šå®šä¹‰ CNN æ¨¡å‹ï¼ˆé‡ç‚¹ï¼ç»“åˆç¬¬å…­èŠ‚åŸç†ï¼‰
# ----------------------------

class MNIST_CNN(nn.Module):
    """
    è‡ªå®šä¹‰ CNN æ¨¡å‹ï¼Œç»§æ‰¿è‡ª nn.Moduleï¼ˆPyTorch æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ï¼‰
    """
    def __init__(self):
        super(MNIST_CNN, self).__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        
        # ç¬¬ä¸€ä¸ªå·ç§¯å—ï¼š
        # è¾“å…¥é€šé“æ•° = 1ï¼ˆå› ä¸º MNIST æ˜¯ç°åº¦å›¾ï¼‰
        # è¾“å‡ºé€šé“æ•° = 32ï¼ˆå³ä½¿ç”¨ 32 ä¸ªä¸åŒçš„å·ç§¯æ ¸ â†’ è¾“å‡º 32 å¼ ç‰¹å¾å›¾ï¼‰
        # kernel_size=3ï¼šæ¯ä¸ªå·ç§¯æ ¸æ˜¯ 3Ã—3 å¤§å°ï¼ˆç°ä»£ CNN ä¸»æµé€‰æ‹©ï¼‰
        # padding=1ï¼šåœ¨å›¾åƒè¾¹ç¼˜è¡¥ä¸€åœˆ 0ï¼Œä½¿å¾—è¾“å‡ºå°ºå¯¸ = è¾“å…¥å°ºå¯¸ï¼ˆsame paddingï¼‰
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        
        # ç¬¬ä¸€ä¸ªæ± åŒ–å±‚ï¼š2Ã—2 æœ€å¤§æ± åŒ–ï¼Œæ­¥é•¿=2 â†’ è¾“å‡ºå°ºå¯¸å‡åŠ
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # ç¬¬äºŒä¸ªå·ç§¯å—ï¼š
        # è¾“å…¥é€šé“æ•° = 32ï¼ˆä¸Šä¸€å±‚è¾“å‡ºçš„é€šé“æ•°ï¼‰
        # è¾“å‡ºé€šé“æ•° = 64ï¼ˆä½¿ç”¨ 64 ä¸ªæ–°å·ç§¯æ ¸ï¼‰
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # å±•å¹³å±‚ï¼šå°†å¤šç»´ç‰¹å¾å›¾æ‹‰æˆä¸€ç»´å‘é‡ï¼Œä»¥ä¾¿è¾“å…¥å…¨è¿æ¥å±‚
        # ä¾‹å¦‚ï¼š[64, 7, 7] â†’ [64*7*7] = [3136]
        self.flatten = nn.Flatten()
        
        # å…¨è¿æ¥å±‚ï¼ˆåˆ†ç±»å¤´ï¼‰ï¼š
        # è¾“å…¥ç»´åº¦ = 64 * 7 * 7 = 3136ï¼ˆç”±å‰é¢å·ç§¯+æ± åŒ–å†³å®šï¼‰
        # è¾“å‡ºç»´åº¦ = 128ï¼ˆéšè—å±‚ç¥ç»å…ƒæ•°ï¼‰
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        
        # æœ€ç»ˆè¾“å‡ºå±‚ï¼š10 ä¸ªç¥ç»å…ƒï¼Œå¯¹åº” 0~9 åä¸ªæ•°å­—ç±»åˆ«
        # æ³¨æ„ï¼šè¿™é‡Œä¸åŠ  Softmaxï¼å› ä¸º CrossEntropyLoss å†…éƒ¨å·²åŒ…å«
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­å‡½æ•°ï¼šå®šä¹‰æ•°æ®å¦‚ä½•æµç»ç½‘ç»œ
        x çš„å½¢çŠ¶: [batch_size, 1, 28, 28]
        """
        # ç¬¬ä¸€ä¸ªå·ç§¯å—ï¼šConv â†’ ReLU â†’ Pool
        x = self.conv1(x)          # [B,1,28,28] â†’ [B,32,28,28] ï¼ˆå›  padding=1ï¼‰
        x = torch.relu(x)          # ReLU æ¿€æ´»ï¼šè´Ÿå€¼å˜ 0ï¼Œä¿ç•™æ­£ç‰¹å¾
        x = self.pool1(x)          # [B,32,28,28] â†’ [B,32,14,14] ï¼ˆå°ºå¯¸å‡åŠï¼‰
        
        # ç¬¬äºŒä¸ªå·ç§¯å—
        x = self.conv2(x)          # [B,32,14,14] â†’ [B,64,14,14]
        x = torch.relu(x)
        x = self.pool2(x)          # [B,64,14,14] â†’ [B,64,7,7]
        
        # å±•å¹³ + å…¨è¿æ¥åˆ†ç±»
        x = self.flatten(x)        # [B,64,7,7] â†’ [B, 64*7*7] = [B, 3136]
        x = self.fc1(x)            # [B,3136] â†’ [B,128]
        x = torch.relu(x)          # å†åŠ ä¸€å±‚éçº¿æ€§
        x = self.fc2(x)            # [B,128] â†’ [B,10]ï¼ˆ10 ä¸ªç±»åˆ«çš„ logitsï¼‰
        
        return x  # æ³¨æ„ï¼šè¾“å‡ºæ˜¯ logitsï¼Œä¸æ˜¯æ¦‚ç‡ï¼

# åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼Œå¹¶ç§»è‡³æŒ‡å®šè®¾å¤‡ï¼ˆCPU/GPUï¼‰
model = MNIST_CNN().to(device)
print("\nâœ… æ¨¡å‹ç»“æ„:")
print(model)

# æ‰“å°æ¨¡å‹æ€»å‚æ•°é‡ï¼ˆéªŒè¯æ˜¯å¦åˆç†ï¼‰
total_params = sum(p.numel() for p in model.parameters())
print(f"\nâœ… æ¨¡å‹æ€»å‚æ•°é‡: {total_params:,} ä¸ª")

# ----------------------------
# ç¬¬å…­æ­¥ï¼šè®¾ç½®æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
# ----------------------------

# æŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µï¼ˆé€‚ç”¨äºå¤šåˆ†ç±»ï¼‰
# æ³¨æ„ï¼šPyTorch çš„ CrossEntropyLoss å†…éƒ¨å·²åŒ…å« LogSoftmaxï¼Œ
# æ‰€ä»¥æ¨¡å‹ forward ä¸­**ä¸è¦åŠ  Softmax**ï¼
criterion = nn.CrossEntropyLoss()

# ä¼˜åŒ–å™¨ï¼šAdamï¼ˆè‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œé€šå¸¸æ¯” SGD æ›´å¿«æ”¶æ•›ï¼‰
# model.parameters()ï¼šè‡ªåŠ¨æ”¶é›†æ‰€æœ‰å¯å­¦ä¹ å‚æ•°ï¼ˆåŒ…æ‹¬å·ç§¯æ ¸çš„ w å’Œ bï¼ï¼‰
optimizer = optim.Adam(model.parameters(), lr=0.001)  # å­¦ä¹ ç‡ = 0.001

# ----------------------------
# ç¬¬ä¸ƒæ­¥ï¼šè®­ç»ƒå¾ªç¯ï¼ˆæ ¸å¿ƒï¼ï¼‰
# ----------------------------

print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")

num_epochs = 5  # è®­ç»ƒ 5 ä¸ªå®Œæ•´å‘¨æœŸï¼ˆéå†å…¨éƒ¨è®­ç»ƒæ•°æ® 5 æ¬¡ï¼‰
train_losses = []  # è®°å½•æŸå¤±ï¼Œç”¨äºåç»­ç»˜å›¾

for epoch in range(num_epochs):
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼ˆå½±å“ Dropout/BatchNormï¼Œæœ¬æ¨¡å‹æ— å½±å“ä½†å¥½ä¹ æƒ¯ï¼‰
    running_loss = 0.0  # ç´¯è®¡å½“å‰ epoch çš„æŸå¤±
    
    # enumerate: åŒæ—¶è·å–æ‰¹æ¬¡ç´¢å¼•å’Œæ•°æ®
    for batch_idx, (images, labels) in enumerate(train_loader):
        # å°†æ•°æ®ç§»è‡³è®¾å¤‡ï¼ˆGPU/CPUï¼‰
        images = images.to(device)   # å½¢çŠ¶: [64, 1, 28, 28]
        labels = labels.to(device)   # å½¢çŠ¶: [64]ï¼ˆæ•´æ•°æ ‡ç­¾ 0~9ï¼‰
        
        # === å‰å‘ä¼ æ’­ ===
        outputs = model(images)      # è¾“å‡ºå½¢çŠ¶: [64, 10]ï¼ˆlogitsï¼‰
        loss = criterion(outputs, labels)  # è®¡ç®—æŸå¤±
        
        # === åå‘ä¼ æ’­ ===
        optimizer.zero_grad()        # æ¸…ç©ºä¸Šä¸€æ­¥çš„æ¢¯åº¦ï¼ˆéå¸¸é‡è¦ï¼ï¼‰
        loss.backward()              # è‡ªåŠ¨è®¡ç®—æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ï¼ˆåŒ…æ‹¬å·ç§¯æ ¸ï¼ï¼‰
        optimizer.step()             # ç”¨æ¢¯åº¦æ›´æ–°æ‰€æœ‰å‚æ•°ï¼ˆw å’Œ bï¼‰
        
        # ç´¯è®¡æŸå¤±
        running_loss += loss.item()  # .item() å°†å•å…ƒç´ å¼ é‡è½¬ä¸º Python æ•°
        
        # æ¯ 100 ä¸ª batch æ‰“å°ä¸€æ¬¡å¹³å‡æŸå¤±
        if (batch_idx + 1) % 100 == 0:
            avg_loss = running_loss / 100
            print(f"Epoch [{epoch+1}/{num_epochs}], "
                  f"Step [{batch_idx+1}/{len(train_loader)}], "
                  f"Loss: {avg_loss:.4f}")
            train_losses.append(avg_loss)
            running_loss = 0.0  # é‡ç½®ç´¯è®¡

# ----------------------------
# ç¬¬å…«æ­¥ï¼šæµ‹è¯•å‡†ç¡®ç‡ï¼ˆè¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼‰
# ----------------------------

model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ Dropout ç­‰ï¼‰
correct = 0   # æ­£ç¡®é¢„æµ‹æ•°
total = 0     # æ€»æ ·æœ¬æ•°

# torch.no_grad()ï¼šå…³é—­æ¢¯åº¦è®¡ç®—ï¼ˆèŠ‚çœå†…å­˜ï¼ŒåŠ é€Ÿï¼‰
with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        
        outputs = model(images)                # [B,10] logits
        _, predicted = torch.max(outputs, 1)   # å–æ¯è¡Œæœ€å¤§å€¼çš„ç´¢å¼•ï¼ˆå³é¢„æµ‹ç±»åˆ«ï¼‰
        
        total += labels.size(0)                # ç´¯è®¡æ ·æœ¬æ•°
        correct += (predicted == labels).sum().item()  # ç´¯è®¡æ­£ç¡®æ•°

accuracy = 100 * correct / total
print(f"\nâœ… æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%")

# ----------------------------
# ç¬¬ä¹æ­¥ï¼šå¯è§†åŒ–ï¼ˆéªŒè¯â€œå·ç§¯æ ¸æ˜¯å­¦å‡ºæ¥çš„â€ï¼‰
# ----------------------------

# è·å–ç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„æƒé‡ï¼ˆå³ 32 ä¸ªå·ç§¯æ ¸ï¼‰
# .dataï¼šè·å–å¼ é‡æ•°æ®ï¼ˆä¸å¸¦æ¢¯åº¦ï¼‰
# .cpu()ï¼šç§»å› CPUï¼ˆmatplotlib ä¸èƒ½ç›´æ¥å¤„ç† GPU å¼ é‡ï¼‰
conv1_weights = model.conv1.weight.data.cpu()  # å½¢çŠ¶: [32, 1, 3, 3]

# å¯è§†åŒ–å‰ 16 ä¸ªå·ç§¯æ ¸
plt.figure(figsize=(10, 6))
for i in range(16):
    plt.subplot(4, 4, i+1)
    # conv1_weights[i, 0] æ˜¯ç¬¬ i ä¸ªæ ¸çš„ 3Ã—3 æƒé‡ï¼ˆå•é€šé“ï¼‰
    plt.imshow(conv1_weights[i, 0], cmap='gray', vmin=-1, vmax=1)
    plt.title(f"Kernel {i+1}")
    plt.axis('off')
plt.suptitle('ç¬¬ä¸€å±‚å·ç§¯æ ¸ï¼ˆè®­ç»ƒåï¼Œ32ä¸ªä¸­çš„å‰16ä¸ªï¼‰')
plt.tight_layout()
plt.show()

# å¯è§†åŒ–æŸå¼ æµ‹è¯•å›¾çš„ç‰¹å¾å›¾
sample_image, true_label = test_dataset[0]  # å–ç¬¬ä¸€å¼ æµ‹è¯•å›¾
print(f"\nğŸ” å¯è§†åŒ–ç¬¬ 1 å¼ æµ‹è¯•å›¾ï¼ˆçœŸå®æ ‡ç­¾: {true_label}ï¼‰")

# å¢åŠ  batch ç»´åº¦ï¼š[1,28,28] â†’ [1,1,28,28]
sample_image = sample_image.unsqueeze(0).to(device)

# è·å–ç¬¬ä¸€å±‚å·ç§¯åçš„è¾“å‡ºï¼ˆéœ€ä¸´æ—¶å‰å‘ï¼Œä½†ä¸æ›´æ–°å‚æ•°ï¼‰
with torch.no_grad():
    conv1_output = torch.relu(model.conv1(sample_image))  # [1,32,28,28]

# å¯è§†åŒ–å‰ 16 ä¸ªç‰¹å¾å›¾
plt.figure(figsize=(10, 6))
for i in range(16):
    plt.subplot(4, 4, i+1)
    # conv1_output[0, i] æ˜¯ç¬¬ i ä¸ªç‰¹å¾å›¾ï¼ˆ28Ã—28ï¼‰
    plt.imshow(conv1_output[0, i].cpu(), cmap='viridis')
    plt.title(f"Feature Map {i+1}")
    plt.axis('off')
plt.suptitle('ç¬¬ä¸€å±‚å·ç§¯åçš„ç‰¹å¾å›¾ï¼ˆå¯¹ç¬¬ä¸€å¼ æµ‹è¯•å›¾ï¼‰')
plt.tight_layout()
plt.show()

print("\nğŸ‰ å®æˆ˜å®Œæˆï¼ä½ å·²æˆåŠŸè®­ç»ƒä¸€ä¸ª CNN å¹¶éªŒè¯å…¶å·¥ä½œåŸç†ã€‚")