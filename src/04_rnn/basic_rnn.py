# -*- coding: utf-8 -*-
"""
ç¬¬åä¸€èŠ‚å®æˆ˜ï¼šä½¿ç”¨ LSTM é¢„æµ‹æ¯æ—¥æœ€ä½æ°”æ¸©ï¼ˆæ—¶é—´åºåˆ—å›å½’ï¼‰
æ•°æ®æ¥æºï¼šhttps://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv
ä»»åŠ¡ï¼šç”¨è¿‡å»30å¤©çš„æ°”æ¸©ï¼Œé¢„æµ‹ç¬¬31å¤©çš„æ°”æ¸©ï¼ˆè¿ç»­å€¼ï¼‰
"""

# ----------------------------
# ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥æ‰€éœ€åº“
# ----------------------------

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import MinMaxScaler  # ç”¨äºå½’ä¸€åŒ–
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math
import urllib.request
import os

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°
torch.manual_seed(42)
np.random.seed(42)

# ----------------------------
# ç¬¬äºŒæ­¥ï¼šä¸‹è½½å¹¶åŠ è½½æ•°æ®
# ----------------------------

# æ•°æ® URL
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv"
data_file = "daily-min-temperatures.csv"

# å¦‚æœæœ¬åœ°æ²¡æœ‰ï¼Œå°±ä¸‹è½½
if not os.path.exists(data_file):
    print("ğŸ“¥ æ­£åœ¨ä¸‹è½½æ°”æ¸©æ•°æ®...")
    urllib.request.urlretrieve(url, data_file)
    print(f"âœ… æ•°æ®å·²ä¿å­˜ä¸º {data_file}")

# è¯»å– CSV æ–‡ä»¶
# æ–‡ä»¶æ ¼å¼ï¼šDate,Temp
# ç¤ºä¾‹ï¼š1981-01-01,20.7
df = pd.read_csv(data_file)
print(f"\nğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
print(df.head())

# è½¬æ¢æ—¥æœŸåˆ—ä¸º datetime ç±»å‹ï¼ˆä¾¿äºåç»­å¤„ç†ï¼‰
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date')  # ç¡®ä¿æŒ‰æ—¶é—´æ’åº

# æå–æ°”æ¸©åˆ—ï¼ˆè½¬ä¸º floatï¼Œæ³¨æ„åŸå§‹æ•°æ®å¯èƒ½æœ‰ç©ºæ ¼ï¼‰
df['Temp'] = df['Temp'].astype(str).str.strip()
df['Temp'] = pd.to_numeric(df['Temp'], errors='coerce')  # å°†æ— æ•ˆå€¼è½¬ä¸º NaN

# åˆ é™¤ç¼ºå¤±å€¼
df = df.dropna()
print(f"âœ… æ¸…æ´—åæ•°æ®é‡: {len(df)} å¤©")

# å¯è§†åŒ–åŸå§‹æ°”æ¸©åºåˆ—
plt.figure(figsize=(12, 4))
plt.plot(df['Date'], df['Temp'], color='steelblue')
plt.title('ğŸŒ¡ï¸ æ¾³å¤§åˆ©äºšå¢¨å°”æœ¬æ¯æ—¥æœ€ä½æ°”æ¸© (1981â€“1990)')
plt.xlabel('æ—¥æœŸ')
plt.ylabel('æ°”æ¸© (Â°C)')
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é¢„å¤„ç† â€” å½’ä¸€åŒ– + æ„é€ æ»‘åŠ¨çª—å£
# ----------------------------

# ğŸŒŸ æ–°æ¦‚å¿µï¼šå½’ä¸€åŒ–ï¼ˆNormalizationï¼‰
# ç›®çš„ï¼šå°†æ°”æ¸©ç¼©æ”¾åˆ° [0, 1] åŒºé—´ï¼ŒåŠ é€Ÿè®­ç»ƒã€é¿å…æ¢¯åº¦çˆ†ç‚¸
scaler = MinMaxScaler(feature_range=(0, 1))
temps_scaled = scaler.fit_transform(df['Temp'].values.reshape(-1, 1))  # è½¬ä¸ºåˆ—å‘é‡
temps_scaled = temps_scaled.flatten()  # è½¬å›ä¸€ç»´æ•°ç»„

print(f"\nğŸ” å½’ä¸€åŒ–åæ°”æ¸©èŒƒå›´: [{temps_scaled.min():.3f}, {temps_scaled.max():.3f}]")

# ğŸŒŸ æ–°æ¦‚å¿µï¼šæ»‘åŠ¨çª—å£ï¼ˆSliding Windowï¼‰
# æ€è·¯ï¼šç”¨è¿ç»­ seq_length å¤©çš„æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€å¤©
# ä¾‹å¦‚ï¼š[t1, t2, ..., t30] â†’ t31
seq_length = 30  # ä½¿ç”¨è¿‡å»30å¤©é¢„æµ‹ç¬¬31å¤©

def create_sequences(data, seq_len):
    """
    ä»ä¸€ç»´æ—¶é—´åºåˆ—æ„é€  (X, y) æ ·æœ¬
    :param data: å½’ä¸€åŒ–åçš„ä¸€ç»´æ•°ç»„ï¼Œå¦‚ [0.1, 0.3, 0.5, ...]
    :param seq_len: è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆå¦‚30ï¼‰
    :return: X (æ ·æœ¬æ•°, seq_len, 1), y (æ ·æœ¬æ•°,)
    """
    X, y = [], []
    for i in range(len(data) - seq_len):
        # è¾“å…¥ï¼šä» i åˆ° i+seq_len-1
        X.append(data[i:i + seq_len])
        # è¾“å‡ºï¼ši+seq_len æ—¶åˆ»çš„å€¼
        y.append(data[i + seq_len])
    return np.array(X), np.array(y)

# æ„é€ å…¨éƒ¨æ ·æœ¬
X, y = create_sequences(temps_scaled, seq_length)
print(f"\nğŸ§© æ„é€ çš„æ ·æœ¬æ•°: {X.shape[0]}")
print(f"è¾“å…¥å½¢çŠ¶ X: {X.shape} â†’ (æ ·æœ¬æ•°, æ—¶é—´æ­¥é•¿, ç‰¹å¾æ•°)")
print(f"è¾“å‡ºå½¢çŠ¶ y: {y.shape} â†’ (æ ·æœ¬æ•°,)")

# ----------------------------
# ç¬¬å››æ­¥ï¼šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# ----------------------------

# æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†ï¼ˆä¸èƒ½éšæœºæ‰“ä¹±ï¼ï¼‰
# å‰ 80% ä¸ºè®­ç»ƒé›†ï¼Œå 20% ä¸ºæµ‹è¯•é›†
split_idx = int(0.8 * len(X))
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

print(f"\nâœ… è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
print(f"âœ… æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")

# è½¬ä¸º PyTorch å¼ é‡
X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)  # [N, 30] â†’ [N, 30, 1]
y_train = torch.tensor(y_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)
y_test = torch.tensor(y_test, dtype=torch.float32)

print(f"\nğŸ§  å¼ é‡å½¢çŠ¶ç¡®è®¤:")
print(f"X_train: {X_train.shape} â†’ (batch, seq_len, input_size=1)")
print(f"y_train: {y_train.shape} â†’ (batch,)")

# ----------------------------
# ç¬¬äº”æ­¥ï¼šè‡ªå®šä¹‰ Dataset ç±»ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
# ----------------------------

class TempDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# åˆ›å»º DataLoader
batch_size = 64
train_dataset = TempDataset(X_train, y_train)
test_dataset = TempDataset(X_test, y_test)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  # æ—¶é—´åºåˆ—ä¸ shuffleï¼
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# ----------------------------
# ç¬¬å…­æ­¥ï¼šå®šä¹‰ LSTM å›å½’æ¨¡å‹
# ----------------------------

class LSTMRegressor(nn.Module):
    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1):
        """
        LSTM å›å½’æ¨¡å‹
        :param input_size: æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾æ•°ï¼ˆæ°”æ¸©æ˜¯1ç»´ï¼‰
        :param hidden_size: LSTM éšè—å•å…ƒæ•°
        :param num_layers: LSTM å±‚æ•°
        :param output_size: è¾“å‡ºç»´åº¦ï¼ˆå›å½’ä»»åŠ¡é€šå¸¸ä¸º1ï¼‰
        """
        super(LSTMRegressor, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # ğŸŒŸ æ ¸å¿ƒï¼šLSTM å±‚
        # input_size=1ï¼šå› ä¸ºæ¯å¤©åªæœ‰1ä¸ªæ°”æ¸©å€¼
        # batch_first=Trueï¼šè¾“å…¥å½¢çŠ¶ä¸º (batch, seq_len, input_size)
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)

        # ğŸŒŸ å›å½’è¾“å‡ºå±‚ï¼šå°†æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€æ˜ å°„åˆ°1ä¸ªè¾“å‡ºå€¼
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        :param x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ (batch, seq_len, 1)
        :return: é¢„æµ‹å€¼ï¼Œå½¢çŠ¶ (batch, 1)
        """
        # åˆå§‹åŒ–éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€ï¼ˆå¯é€‰ï¼ŒPyTorch ä¼šè‡ªåŠ¨åˆå§‹åŒ–ä¸º0ï¼‰
        # h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)

        # LSTM å‰å‘ä¼ æ’­
        # output: (batch, seq_len, hidden_size)
        # (hn, cn): æœ€åæ—¶åˆ»çš„éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€
        output, (hn, cn) = self.lstm(x)  # hn å½¢çŠ¶: (num_layers, batch, hidden_size)

        # ğŸŒŸ å…³é”®ï¼šæˆ‘ä»¬åªå…³å¿ƒæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºï¼ˆå³é¢„æµ‹æœªæ¥ä¸€å¤©ï¼‰
        # å– output[:, -1, :] æˆ– hn[-1] éƒ½å¯ä»¥ï¼ˆå•å±‚æ—¶ç­‰ä»·ï¼‰
        last_output = output[:, -1, :]  # (batch, hidden_size)

        # é€šè¿‡å…¨è¿æ¥å±‚å¾—åˆ°æœ€ç»ˆé¢„æµ‹
        out = self.fc(last_output)  # (batch, 1)

        return out.squeeze(-1)  # å»æ‰æœ€åä¸€ç»´ â†’ (batch,)

# åˆ›å»ºæ¨¡å‹
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = LSTMRegressor(input_size=1, hidden_size=50, num_layers=1, output_size=1).to(device)
print(f"\nâœ… æ¨¡å‹å·²åˆ›å»ºï¼Œä½¿ç”¨è®¾å¤‡: {device}")
print(model)

# ----------------------------
# ç¬¬ä¸ƒæ­¥ï¼šè®¾ç½®æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
# ----------------------------

criterion = nn.MSELoss()  # å›å½’ä»»åŠ¡å¸¸ç”¨ MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# ----------------------------
# ç¬¬å…«æ­¥ï¼šè®­ç»ƒæ¨¡å‹
# ----------------------------

print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")

num_epochs = 50
train_losses = []

for epoch in range(num_epochs):
    model.train()
    total_loss = 0.0

    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)

        # å‰å‘ä¼ æ’­
        outputs = model(inputs)  # outputs: (batch,)
        loss = criterion(outputs, targets)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    train_losses.append(avg_loss)

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}")

# ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
plt.figure(figsize=(8, 4))
plt.plot(train_losses, label='Training Loss')
plt.title('ğŸ“‰ è®­ç»ƒæŸå¤±æ›²çº¿')
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.legend()
plt.grid(True)
plt.show()

# ----------------------------
# ç¬¬ä¹æ­¥ï¼šåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
# ----------------------------

model.eval()
test_preds = []
test_targets = []

with torch.no_grad():
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        test_preds.extend(outputs.cpu().numpy())
        test_targets.extend(targets.cpu().numpy())

# åå½’ä¸€åŒ–ï¼ˆå°†é¢„æµ‹å€¼å’ŒçœŸå®å€¼è½¬å›åŸå§‹æ°”æ¸©å•ä½ï¼‰
test_preds = np.array(test_preds).reshape(-1, 1)
test_targets = np.array(test_targets).reshape(-1, 1)

test_preds_original = scaler.inverse_transform(test_preds).flatten()
test_targets_original = scaler.inverse_transform(test_targets).flatten()

# è®¡ç®—å›å½’æŒ‡æ ‡
mae = mean_absolute_error(test_targets_original, test_preds_original)
rmse = math.sqrt(mean_squared_error(test_targets_original, test_preds_original))

print(f"\nğŸ‰ æµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.2f} Â°C")
print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.2f} Â°C")

# ----------------------------
# ç¬¬åæ­¥ï¼šå¯è§†åŒ–é¢„æµ‹ç»“æœ
# ----------------------------

plt.figure(figsize=(14, 6))
plt.plot(test_targets_original, label='çœŸå®æ°”æ¸©', color='steelblue')
plt.plot(test_preds_original, label='LSTM é¢„æµ‹', color='orange', linestyle='--')
plt.title('ğŸŒ¡ï¸ LSTM æ°”æ¸©é¢„æµ‹ç»“æœï¼ˆæµ‹è¯•é›†ï¼‰')
plt.xlabel('æ—¶é—´æ­¥ï¼ˆå¤©ï¼‰')
plt.ylabel('æœ€ä½æ°”æ¸© (Â°C)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ----------------------------
# ç¬¬åä¸€ï¼šé¢„æµ‹æœªæ¥ä¸€å¤©ï¼ˆæ¼”ç¤ºï¼‰
# ----------------------------

def predict_next_day(model, last_sequence, scaler, device):
    """
    ä½¿ç”¨æœ€è¿‘ seq_length å¤©çš„æ•°æ®é¢„æµ‹ä¸‹ä¸€å¤©æ°”æ¸©
    :param model: è®­ç»ƒå¥½çš„ LSTM æ¨¡å‹
    :param last_sequence: æœ€è¿‘ seq_length å¤©çš„å½’ä¸€åŒ–æ°”æ¸©ï¼ˆä¸€ç»´æ•°ç»„ï¼‰
    :param scaler: å½’ä¸€åŒ–å™¨
    :param device: CPU/GPU
    :return: é¢„æµ‹çš„åŸå§‹æ°”æ¸©å€¼
    """
    # è½¬ä¸ºå¼ é‡å¹¶å¢åŠ  batch å’Œ feature ç»´åº¦
    input_tensor = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)  # [1, 30, 1]
    input_tensor = input_tensor.to(device)

    model.eval()
    with torch.no_grad():
        pred = model(input_tensor)  # [1,]
        pred_scaled = pred.cpu().item()
        pred_original = scaler.inverse_transform([[pred_scaled]])[0, 0]
    return pred_original

# ç¤ºä¾‹ï¼šç”¨æµ‹è¯•é›†æœ€å30å¤©é¢„æµ‹â€œæœªæ¥ä¸€å¤©â€
last_30_days = temps_scaled[-seq_length:]  # æœ€å30å¤©çš„å½’ä¸€åŒ–æ•°æ®
future_pred = predict_next_day(model, last_30_days, scaler, device)
print(f"\nğŸ”® åŸºäºæœ€è¿‘30å¤©æ°”æ¸©ï¼Œé¢„æµ‹ä¸‹ä¸€å¤©æœ€ä½æ°”æ¸©: {future_pred:.2f} Â°C")